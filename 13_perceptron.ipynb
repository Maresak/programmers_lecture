{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공신경망\n",
    "## 퍼셉트론\n",
    "- 인공신경망의 한 종류\n",
    "- 가장 간단한 형태의 피드포워드 네트워크 (선형 분류기)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Learning Perceptron in Python\n",
    "파이썬으로 표준 라이브러리를 사용해서 위의 퍼셉트론 알고리즘을 구현했기 때문에 스크립트가 PyPy에서 실행되고 3-4배의 속도향상이 있다. 여기에 사용된 알고리즘은 Kaggle 포럼에서 처음 발견 된 tinrtgu의 온라인 로지스틱 회귀 스크립트에서 큰 영감을 얻었다고 한다.\n",
    "- 다음 경진대회에서 Vowpal Wabbit을 통한 해시트릭을 사용하였고 코드가 공개되어 있다.\n",
    "- Display Advertising Challenge - Kaggle, Beat the benchmark with less then 200MB of memory.\n",
    "- 코드 : https://kaggle2.blob.core.windows.net/forum-message-attachments/53646/1539/fast_solution.py\n",
    "\n",
    "# 온라인 학습\n",
    "퍼셉트론은 온라인 학습이 가능하다(한 번에 하나씩 샘플을 통해 학습). 메모리에 전체 데이터 세트가 필요하지 않으므로(out-of-core) 더 큰 데이터 세트에 유용하다. 여기에서는 Vowpal Wabbit에서 온라인 학습 코드를 가져왔다.\n",
    "- Vowpal Wabbit (Fast Learning) : http://hunch.net/~vw/\n",
    "- Hashing Representations : http://hunch.net/~jl/projects/hash_reps/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 해싱 트릭\n",
    "#### 메모리를 적게 사용할 수 있다\n",
    "벡터화 해싱 트릭은 Vowpal Wabbit(John Langford)에서 시작되었다. 이 트릭은 퍼셉트론으로 들어오는 연결 수를 고정 된 크기로 설정한다. 고정 된 크기보다 낮은 숫자로 모든 원시 피처를 해싱한다. Vowpal Wabbit은 모든 데이터를 메모리로 읽어들이지 않고 모델을 훈련 시킬 수 있는 빠른 머신러닝 라이브러리다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'movie', 'sucks']\n",
      "[(705, 1), (335, 1), (450, 1)]\n"
     ]
    }
   ],
   "source": [
    "sample = \"This movie sucks\"\n",
    "fixed_size = 1024\n",
    "\n",
    "print(sample.split())\n",
    "\n",
    "features = [(hash(f)%fixed_size, 1) for f in sample.split()]\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로그레시브 검증 손실\n",
    "- 한 번에 하나씩 표본을 학습하면 점진적으로 train loss가 된다. 모델이 타겟을 보지않고 첫 샘플을 보고 예측을 한다.\n",
    "- 그런 다음 예측을 대상 레이블과 비교하여 오류율을 계산 한다. 오류율이 낮으면 좋은 모델에 가깝다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple passes\n",
    "- Vowpal Wabbit을 사용하면 학습률이 떨어지는 데이터 집합을 여러 번 통과시킬 수 있다.\n",
    "- 오류율이 낮아지면 데이터 세트를 여러 번 실행할 수도 있다. 트레이닝 데이터가 선형 적으로 분리 가능한 경우, 퍼셉트론은 트레이닝 세트에서 오차가 0으로 수렴된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33554432"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opts[\"D\"] 여기에 있는 코드에서는 고정 값으로 다음의 값을 사용한다.\n",
    "2 ** 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # 정규표현식으로 텍스트 데이터를 정제\n",
    "import random\n",
    "from math import exp, log # 지수, 로그 함수 사용\n",
    "from datetime import datetime # 시간 계산\n",
    "from operator import itemgetter # 키가 아닌 값으로 max, min 값을 구할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    '''\n",
    "    텍스트 정제, 소문자로 변환\n",
    "    '''\n",
    "    return \" \".join(re.findall(r'\\w+', s, flags = re.UNICODE)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tsv(loc_dataset, opts):\n",
    "    '''\n",
    "    온라인 학습 방법을 통해 데이터를 실행한다.\n",
    "    tsv파일을 통해 레이블, identifier, 피처(특성)를 파싱한다.\n",
    "    결과물:\n",
    "        label : int, 레이블 / 대상 (테스트 집합 인 경우 \"1\"로 설정)\n",
    "        id : 문자열, 샘플 식별자\n",
    "        features : [(hashed_feature_index, feature_value)] \n",
    "                형식의 튜플 목록    \n",
    "    '''\n",
    "    for e, line in enumerate(open(loc_dataset, \"rb\")):\n",
    "        if e > 0:\n",
    "            r = line.decode('utf-8').strip().split('\\t')\n",
    "            id = r[0]\n",
    "            \n",
    "            if opts['clean']:\n",
    "                try:\n",
    "                    r[2] = clean(r[2]) # train\n",
    "                except:\n",
    "                    r[1] = clean(r[1]) # test\n",
    "            \n",
    "            # opts[\"D\"] = 2 ** 25 = 33554432\n",
    "            # Vowpal Wabbit의 해싱트릭을 사용한다.\n",
    "            # 해싱트릭은 큰 규모의 feature공간을 고정크기의 표현을 사용해 저장할 수 있게 한다.\n",
    "            \n",
    "            if len(r) == 3: # train set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[2].split()]\n",
    "                label = int(r[1])\n",
    "            else: # test set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[1].split()]\n",
    "                label = 1\n",
    "                \n",
    "            # bigram을 사용하면 해당 피처[i]와 다음피처[i+1]를 함께 해싱한다.\n",
    "            if opts[\"2grams\"]:\n",
    "                for i in range(len(features)-1):\n",
    "                    features.append(\n",
    "                        (hash(str(features[i][0])+str(features[i+1][0]))%opts[\"D\"],1))\n",
    "            yield label, id, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(features, weights):\n",
    "    \"\"\"\n",
    "    피처(특성)과 가중치로부터 내적을 구한다.\n",
    "    \"\"\"\n",
    "    dotp = 0\n",
    "    for f in features:\n",
    "        dotp += weights[f[0]] * f[1]\n",
    "        \n",
    "    return dotp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tron(loc_dataset, opts):\n",
    "    start = datetime.now()\n",
    "    print(\"\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "    \n",
    "    # 가중치 초기화\n",
    "    if opts[\"random_init\"]:\n",
    "        random.seed(3003)\n",
    "        weights = [random.random()] * opts[\"D\"]\n",
    "    else:\n",
    "        weights = [0.] * opts[\"D\"]\n",
    "        \n",
    "    # 학습 실행\n",
    "    for pass_nr in range(opts[\"n_passes\"]):\n",
    "        error_counter = 0\n",
    "        for e, (label, id, features) in enumerate( get_data_tsv(loc_dataset,opts) ):\n",
    "            \n",
    "            # 퍼셉트론은 지도학습 분류기의 일종이다. \n",
    "            # 이전 값에 대한 학습으로 예측을 한다. \n",
    "            # 내적(dotproduct) 값이 임계 값보다 높거나 낮은지에 따라 \n",
    "            # 초과하면 \"1\"을 예측하고 미만이면 \"0\"을 예측한다.\n",
    "            dp = dot_product(features, weights) > 0.5\n",
    "            \n",
    "            # 다음 perceptron은 샘플의 레이블을 본다. \n",
    "            # 실제 레이블 데이터에서 위 퍼셉트론으로 구한 dp값을 빼준다.\n",
    "            # 예측이 정확하다면, error 값은 \"0\"이며, 가중치만 남겨 둔다. \n",
    "            # 예측이 틀린 경우 error 값은 \"1\" 또는 \"-1\"이고 다음과 같이 가중치를 업데이트 한다.\n",
    "            # weights[feature_index] += learning_rate * error * feature_value\n",
    "            error = label - dp\n",
    "            \n",
    "            # 예측이 틀리면 퍼셉트론은 가중치를 업데이트\n",
    "            if error != 0:\n",
    "                error_counter += 1\n",
    "                # Updating the weights\n",
    "                for index, value in features:\n",
    "                    weights[index] += opts[\"learning_rate\"] * error * log(1.+value)\n",
    "                    \n",
    "        #Reporting stuff\n",
    "        print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s\" % ( \\\n",
    "            pass_nr+1,\n",
    "            error_counter,\n",
    "            round(1 - error_counter /float(e+1),5),\n",
    "            e+1,datetime.now()-start))\n",
    "        \n",
    "        # error_counter가 0 이거나 오버피팅되는 경우면 중지\n",
    "        if error_counter == 0 or error_counter < opts[\"errors_satisfied\"]:\n",
    "            print(\"%s errors found during training, halting\"%error_counter)\n",
    "            break\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tron(loc_dataset, weights, opts):\n",
    "    \"\"\"\n",
    "        output:\n",
    "                preds: list, a list with\n",
    "                [id,prediction,dotproduct,0-1normalized dotproduct]\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    print(\"\\nTesting online\\nErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "    \n",
    "    # 값 초기화\n",
    "    preds = []\n",
    "    error_counter = 0\n",
    "    for e, (label, id, features) in enumerate( get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "        dotp = dot_product(features, weights)\n",
    "        # 내적이 0.5보다 크다면 긍정으로 예측한다.\n",
    "        dp = dotp > 0.5\n",
    "        if dp > 0.5: # we predict positive class\n",
    "            preds.append( [id, 1, dotp ] )\n",
    "        else:\n",
    "            preds.append( [id, 0, dotp ] )\n",
    "    \n",
    "        # get_data_tsv에서 테스트 데이터의 레이블을 1로 초기화해주었음\n",
    "        if label - dp != 0:\n",
    "            error_counter += 1\n",
    "            \n",
    "    print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (\n",
    "        error_counter,\n",
    "        round(1 - error_counter /float(e+1),5),\n",
    "        e+1,\n",
    "        datetime.now()-start))\n",
    "    \n",
    "    # 내적을 구해 0과 1로 일반화 한다.\n",
    "    # TODO: proper probability (bounded sigmoid?), \n",
    "    # online normalization\n",
    "    max_dotp = max(preds,key=itemgetter(2))[2]\n",
    "    min_dotp = min(preds,key=itemgetter(2))[2]\n",
    "    # 정규화된 값을 마지막에 추가\n",
    "    # (피처와 가중치에 대한 내적값 - 최소 내적값) / 최대 내적값 - 최소 내적값\n",
    "    for p in preds:\n",
    "        p.append((p[2]-min_dotp)/float(max_dotp-min_dotp))\n",
    "        \n",
    "    #Reporting stuff\n",
    "    print(\"Done testing in %s\"%str(datetime.now()-start))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵션 세팅\n",
    "opts = {}\n",
    "opts[\"D\"] = 2 ** 25\n",
    "opts[\"learning_rate\"] = 0.1\n",
    "opts[\"n_passes\"] = 80 # Maximum number of passes to run before halting (for 루프를 몇 번 돌건지)\n",
    "opts[\"errors_satisfied\"] = 0 # Halt when training errors < errors_satisfied (error가 0이어야만 멈춘다)\n",
    "opts[\"random_init\"] = False # set random weights, else set all 0 (랜덤값 사용여부)\n",
    "opts[\"clean\"] = True # clean the text a little (데이터 정제)\n",
    "opts[\"2grams\"] = True # add 2grams (바이그램 사용 여부)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pass\t\tErrors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "1\t\t5690\t\t0.7724\t\t25000\t\t0:00:13.213260\n",
      "2\t\t3087\t\t0.87652\t\t25000\t\t0:00:24.311678\n",
      "3\t\t2188\t\t0.91248\t\t25000\t\t0:00:35.446354\n",
      "4\t\t1601\t\t0.93596\t\t25000\t\t0:00:48.621787\n",
      "5\t\t1277\t\t0.94892\t\t25000\t\t0:00:59.910257\n",
      "6\t\t997\t\t0.96012\t\t25000\t\t0:01:10.454385\n",
      "7\t\t886\t\t0.96456\t\t25000\t\t0:01:21.052189\n",
      "8\t\t701\t\t0.97196\t\t25000\t\t0:01:31.733266\n",
      "9\t\t512\t\t0.97952\t\t25000\t\t0:01:42.290155\n",
      "10\t\t482\t\t0.98072\t\t25000\t\t0:01:52.922136\n",
      "11\t\t333\t\t0.98668\t\t25000\t\t0:02:03.431161\n",
      "12\t\t288\t\t0.98848\t\t25000\t\t0:02:13.868452\n",
      "13\t\t242\t\t0.99032\t\t25000\t\t0:02:24.414194\n",
      "14\t\t183\t\t0.99268\t\t25000\t\t0:02:34.957586\n",
      "15\t\t196\t\t0.99216\t\t25000\t\t0:02:45.507495\n",
      "16\t\t173\t\t0.99308\t\t25000\t\t0:02:57.204046\n",
      "17\t\t145\t\t0.9942\t\t25000\t\t0:03:08.289193\n",
      "18\t\t190\t\t0.9924\t\t25000\t\t0:03:19.045930\n",
      "19\t\t110\t\t0.9956\t\t25000\t\t0:03:29.716936\n",
      "20\t\t148\t\t0.99408\t\t25000\t\t0:03:40.309897\n",
      "21\t\t117\t\t0.99532\t\t25000\t\t0:03:50.939257\n",
      "22\t\t92\t\t0.99632\t\t25000\t\t0:04:01.508224\n",
      "23\t\t103\t\t0.99588\t\t25000\t\t0:04:12.109280\n",
      "24\t\t77\t\t0.99692\t\t25000\t\t0:04:22.637463\n",
      "25\t\t91\t\t0.99636\t\t25000\t\t0:04:33.253767\n",
      "26\t\t88\t\t0.99648\t\t25000\t\t0:04:43.844808\n",
      "27\t\t86\t\t0.99656\t\t25000\t\t0:04:54.433761\n",
      "28\t\t27\t\t0.99892\t\t25000\t\t0:05:05.093606\n",
      "29\t\t42\t\t0.99832\t\t25000\t\t0:05:16.349092\n",
      "30\t\t53\t\t0.99788\t\t25000\t\t0:05:27.426704\n",
      "31\t\t48\t\t0.99808\t\t25000\t\t0:05:38.050733\n",
      "32\t\t36\t\t0.99856\t\t25000\t\t0:05:48.960649\n",
      "33\t\t26\t\t0.99896\t\t25000\t\t0:05:59.789651\n",
      "34\t\t21\t\t0.99916\t\t25000\t\t0:06:10.462611\n",
      "35\t\t10\t\t0.9996\t\t25000\t\t0:06:21.313273\n",
      "36\t\t12\t\t0.99952\t\t25000\t\t0:06:31.927518\n",
      "37\t\t33\t\t0.99868\t\t25000\t\t0:06:42.462504\n",
      "38\t\t0\t\t1.0\t\t25000\t\t0:06:53.265482\n",
      "0 errors found during training, halting\n",
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "#training and saving model into weights\n",
    "%time weights = train_tron(\"word_tutorial/labeledTrainData.tsv\",opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing online\n",
      "Errors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "12290\t\t0.5084\t\t25000\t\t0:00:09.715700\n",
      "Done testing in 0:00:09.723679\n",
      "Wall time: 9.72 s\n"
     ]
    }
   ],
   "source": [
    "# testing and saving predictions into preds\n",
    "%time preds = test_tron(\"word_tutorial/testData.tsv\",weights,opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\"12311_10\"', 1, 74.92921021852996, 0.6381828805141688],\n",
       " ['\"8348_2\"', 0, -94.96116373671242, 0.4591732398480865],\n",
       " ['\"5828_4\"', 1, 6.584898215319436, 0.5661700262927256],\n",
       " ['\"7186_2\"', 0, -3.0498475944637784, 0.556018112766579],\n",
       " ['\"12128_7\"', 1, 35.14256205438916, 0.5962605901256207],\n",
       " ['\"2913_8\"', 1, 67.7897942587626, 0.6306602395559451],\n",
       " ['\"4396_1\"', 0, -33.68695297521327, 0.5237364884604149],\n",
       " ['\"395_2\"', 0, -11.159669607015141, 0.5474729769208296],\n",
       " ['\"10616_1\"', 0, -88.16832136722492, 0.4663307040607655],\n",
       " ['\"9074_9\"', 0, -28.280404966845783, 0.5294332456909144]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preds에서 4번째 있는 것이 정규화한 값이다\n",
    "### 2번째는 판정한 결과값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>74.929210</td>\n",
       "      <td>0.638183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-94.961164</td>\n",
       "      <td>0.459173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>1</td>\n",
       "      <td>6.584898</td>\n",
       "      <td>0.566170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.049848</td>\n",
       "      <td>0.556018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>35.142562</td>\n",
       "      <td>0.596261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"2913_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>67.789794</td>\n",
       "      <td>0.630660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"4396_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-33.686953</td>\n",
       "      <td>0.523736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"395_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.159670</td>\n",
       "      <td>0.547473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"10616_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-88.168321</td>\n",
       "      <td>0.466331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"9074_9\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-28.280405</td>\n",
       "      <td>0.529433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  1          2         3\n",
       "0  \"12311_10\"  1  74.929210  0.638183\n",
       "1    \"8348_2\"  0 -94.961164  0.459173\n",
       "2    \"5828_4\"  1   6.584898  0.566170\n",
       "3    \"7186_2\"  0  -3.049848  0.556018\n",
       "4   \"12128_7\"  1  35.142562  0.596261\n",
       "5    \"2913_8\"  1  67.789794  0.630660\n",
       "6    \"4396_1\"  0 -33.686953  0.523736\n",
       "7     \"395_2\"  0 -11.159670  0.547473\n",
       "8   \"10616_1\"  0 -88.168321  0.466331\n",
       "9    \"9074_9\"  0 -28.280405  0.529433"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "presult = pd.DataFrame(preds)\n",
    "presult.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    12710\n",
       "0    12290\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentiment = presult[1].value_counts()\n",
    "print(output_sentiment[0] - output_sentiment[1])\n",
    "output_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단일 노드 단일 레이어 퍼셉트론은 비선형 함수를 모델링 할 수 없으므로 더 나은 NLP 출력을 얻으려면 FFN(feedforward nets), recurrent nets, self-organizing maps, MLP(Multi-layer Perceptrons), word2vec 및 extreme learning machine (백프로파게이션이 없는 fast ffnets)을 봐야할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
